{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Форматы данных (2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. \"Лекция 5: Форматы данных (часть 2)\"\n",
    "* https://docs.python.org/3/library/csv.html\n",
    "* https://docs.h5py.org/en/stable/\n",
    "* Уэс Маккини. Python и анализ данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задачи для совместного разбора"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Считайте данные из файла `open_pubs.csv`, используя `csv.reader`, и преобразуйте к структуре данных следующего вида:\n",
    "    \n",
    "`{'fas_id': [24, 30, ...], 'name': ['Achor Inn', 'Angel Inn', ...], ... }`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "\n",
    "def pprint_dict_of_lists(dct, m=3):\n",
    "    pprint.pprint({k: [*v[:m], '...', *v[-m:]] for k, v in list(dct.items())})\n",
    "\n",
    "\n",
    "with open(\"./data/open_pubs.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    headers = next(reader)\n",
    "    data = {header: [] for header in headers}\n",
    "\n",
    "    for row in reader:\n",
    "        for i in range(len(headers)):\n",
    "            data[headers[i]].append(row[i])\n",
    "\n",
    "pprint_dict_of_lists(data)  # реально круто!\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'address': ['Upper Street, Stratford St Mary, COLCHESTER, Essex',\n",
      "             'Egremont Street, Glemsford, SUDBURY, Suffolk',\n",
      "             '7 Market Hill, SUDBURY, Suffolk',\n",
      "             '...',\n",
      "             'Wrexham Rugby Club, Bryn Estyn Road, Wrexham, LL13 9TY',\n",
      "             'Y Tai, Railway Road, Brymbo, Wrexham',\n",
      "             'Yew Tree Inn, High Street, Gresford, Wrexham'],\n",
      " 'easting': ['604748', '582888', '587356', '...', '335837', '329598', '334721'],\n",
      " 'fas_id': ['24', '30', '63', '...', '514810', '514814', '514817'],\n",
      " 'latitude': ['51.97039',\n",
      "              '52.094427',\n",
      "              '52.038683',\n",
      "              '...',\n",
      "              '53.05379',\n",
      "              '53.077611',\n",
      "              '53.08797'],\n",
      " 'local_authority': ['Babergh',\n",
      "                     'Babergh',\n",
      "                     'Babergh',\n",
      "                     '...',\n",
      "                     'Wrexham',\n",
      "                     'Wrexham',\n",
      "                     'Wrexham'],\n",
      " 'longitude': ['0.979328',\n",
      "               '0.668408',\n",
      "               '0.730226',\n",
      "               '...',\n",
      "               '-2.958706',\n",
      "               '-3.05237',\n",
      "               '-2.976144'],\n",
      " 'name': ['Anchor Inn',\n",
      "          'Angel Inn',\n",
      "          'Black Boy Hotel',\n",
      "          '...',\n",
      "          'Wrexham Rugby Club',\n",
      "          'Y Tai',\n",
      "          'Yew Tree Inn'],\n",
      " 'northing': ['234405',\n",
      "              '247368',\n",
      "              '241327',\n",
      "              '...',\n",
      "              '351156',\n",
      "              '353894',\n",
      "              '354974'],\n",
      " 'postcode': ['CO7 6LW',\n",
      "              'CO10 7SA',\n",
      "              'CO10 2EA',\n",
      "              '...',\n",
      "              'LL13 9TY',\n",
      "              'LL11 5EA',\n",
      "              'LL12 8RF']}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Сгенерируйте 2 случайные матрицы размера 10_000 x 10_000 и вычислите их произведение. Сколько времени занимают три этих операции? Сохраните 3 полученных матрицы в файл .npz с соответствующими названиями"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer\n",
    "\n",
    "start = default_timer()\n",
    "size = (2000, 2000)\n",
    "A = np.random.randint(0, 100, size=size, dtype=np.int8)\n",
    "B = np.random.randint(0, 100, size=size, dtype=np.int8)\n",
    "C = np.dot(A, B)\n",
    "\n",
    "print(f'time: {(default_timer() - start) * 1000:.4f} ms')\n",
    "\n",
    "np.savez(\"./data/out/result.npz\", A, B, C)\n",
    "# time: 8649.8260 ms"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 8649.8260 ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Создайте 2 матрицы размера 1000x1000, используя различные параметризируемые распределения из numpy (https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html#distributions)\n",
    "\n",
    "После этого сохраните получившиеся матрицы в hdf5-файл в виде двух различных датасетов. В качестве описания каждого датасета укажите параметры используемых распределений "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import h5py\n",
    "A = np.random.uniform(0, 100, size=(1000, 1000)) # непрерывное равномерное распределение\n",
    "B = np.random.binomial(100, 0.5, size=(1000, 1000))\n",
    "\n",
    "with h5py.File(\"./data/out/test.h5\", \"w\") as hdf:\n",
    "    ds1 = hdf.create_dataset(\"arrA\", data=A)\n",
    "    ds2 = hdf.create_dataset(\"arrB\", data=B)\n",
    "\n",
    "    ds1.attrs[\"Description\"] = \"Array A with uniform distribution\"\n",
    "    ds2.attrs[\"Description\"] = \"Array B with binomial distribution\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "with h5py.File(\"./data/out/test.h5\", \"r\") as hdf:\n",
    "    for k in hdf.keys():\n",
    "        ds1 = hdf[k]\n",
    "        print(ds1.attrs['Description'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array A with uniform distribution\n",
      "(1000, 1000)\n",
      "Array B with binomial distribution\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Лабораторная работа 5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 В файле `tags_sample.csv` находится информация о тэгах, приписываемых рецептам. Воспользовавшись `csv.reader`, считайте этот файл и создайте словарь вида `id_рецепта: [список тэгов]`. Сохраните этот словарь в файл `tags_sample.json`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import csv\n",
    "with open(\"./data/tags_sample.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    print(type(reader))\n",
    "    # for row in reader:\n",
    "        # print(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class '_csv.reader'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Считайте файл `recipes_sample_with_filled_nsteps.csv` (__ЛР4__) в виде `pd.DataFrame`. Добавьте к таблице 2 столбца: `n_tags`, содержащий количество тэгов у этого рецепта; и `tags`, содержащий набор тэгов в виде строки (тэги внутри строки разделяются символом `;`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/recipes_sample_with_filled_nsteps.csv\", sep=\",\")\n",
    "print(df)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                               name      id  minutes  \\\n",
      "0             george s at the cove  black bean soup   44123       90   \n",
      "1                healthy for them  yogurt popsicles   67664       10   \n",
      "2                      i can t believe it s spinach   38798       30   \n",
      "3                              italian  gut busters   35173       45   \n",
      "4          love is in the air  beef fondue   sauces   84797       25   \n",
      "...                                             ...     ...      ...   \n",
      "29995  zurie s holey rustic olive and cheddar bread  267661       80   \n",
      "29996          zwetschgenkuchen  bavarian plum cake  386977      240   \n",
      "29997   zwiebelkuchen   southwest german onion cake  103312       75   \n",
      "29998                                   zydeco soup  486161       60   \n",
      "29999        cookies by design   cookies on a stick  298512       29   \n",
      "\n",
      "       contributor_id   submitted  n_steps  \\\n",
      "0               35193  2002-10-25       11   \n",
      "1               91970  2003-07-26        3   \n",
      "2                1533  2002-08-29        5   \n",
      "3               22724  2002-07-27        7   \n",
      "4                4470  2004-02-23        4   \n",
      "...               ...         ...      ...   \n",
      "29995          200862  2007-11-25       16   \n",
      "29996          177443  2009-08-24       22   \n",
      "29997          161745  2004-11-03       10   \n",
      "29998          227978  2012-08-29        7   \n",
      "29999          506822  2008-04-15        9   \n",
      "\n",
      "                                             description  n_ingredients  \n",
      "0      an original recipe created by chef scott meska...           18.0  \n",
      "1      my children and their friends ask for my homem...            NaN  \n",
      "2                these were so go, it surprised even me.            8.0  \n",
      "3      my sister-in-law made these for us at a family...            NaN  \n",
      "4      i think a fondue is a very romantic casual din...            NaN  \n",
      "...                                                  ...            ...  \n",
      "29995  this is based on a french recipe but i changed...           10.0  \n",
      "29996  this is a traditional fresh plum cake, thought...           11.0  \n",
      "29997  this is a traditional late summer early fall s...            NaN  \n",
      "29998  this is a delicious soup that i originally fou...            NaN  \n",
      "29999  i've heard of the 'cookies by design' company,...           10.0  \n",
      "\n",
      "[30000 rows x 8 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.3 В файле `ingredients_sample.csv` находится информация о ингредиентах, необходимых для рецепта. Воспользовавшись `csv.DictReader`, считайте этот файл и создайте словарь вида `id_рецепта: [список ингредиентов]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.4 Добавьте к таблице из задания 1.2 столбец `ingredients`, содержащий набор ингредиентов в виде строки (ингредиенты внутри строки разделяются символом `*`)\n",
    "\n",
    "Для строк, которые содержат пропуски в столбце `n_ingredients`, заполните их на основе файла  `ingredients_sample.csv`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.5 Проверьте, содержит ли столбец `n_ingredients` пропуски. Если нет, треобразуйте его к целочисленному типу и сохраните результаты в файл `recipes_sample_with_tags_ingredients.csv`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### npy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1 Разделите таблицу, полученную в результате 1.5, на две таблицы: одна содержит рецепты, загруженные до 2000 года; вторая - все остальные. В полученных таблицах оставьте только числовые столбцы и преобразуйте их к `numpy.array`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.2. Сохраните 2 полученных массива в архив `npz`. Дайте массивам читаемые имена."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.3 Считайте созданный архив и продемонстрируйте, что данные считались корректно. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### hdf"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.1 Выведите названия всех датасетов, находящихся в файле `nutrition_sample.h5`, а также размерность матриц, содержащихся в данных датасетах и их метаданные.\n",
    "\n",
    "Формат вывода:\n",
    "```\n",
    "Dataset name=dataset_0, dataset size=(30000,), metadata={'info': 'calories (#)'}\n",
    "Dataset name=dataset_1, dataset size=(30000,), metadata={'info': 'total fat (PDV)'}\n",
    "...\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.2 Разбейте каждый из имеющихся датасетов на две части: 1 часть содержит только те строки, где PDV (Percent Daily Value) превышает 100%; 2 часть содержит те строки, где PDV не составляет не более 100%. Создайте 2 группы в файле и разместите в них соответствующие части датасета c сохранением метаданных исходных датасетов. Итого должно получиться 2 группы, содержащие несколько датасетов. Сохраните результаты в файл `nutrition_grouped.h5`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.3 Выведите названия всех групп и датасетов, находящихся в этих группах, из файла `nutrition_grouped.h5` а также размерность матриц, содержащихся в датасетах и их метаданные."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.4 Модифицируйте код из 3.3 таким образом, чтобы сохранить датасеты, используя сжатие. Сравните размер полученного файла с размерами файла из 3.3. Прокомментируйте результат."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}